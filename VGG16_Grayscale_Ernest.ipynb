{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-65_Io1051N",
        "outputId": "89265978-7f39-478d-f396-e2c64943b157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSBFAxfQ-fct"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B9fQpNVs1Lsm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.engine.sequential import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, AveragePooling2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import Model\n",
        "from keras import metrics\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUryyyRb-aEo"
      },
      "source": [
        "## Reading in Dataset to Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_-OtzIM2Ozh",
        "outputId": "0704e6a2-18dd-4aa8-e33c-cd3150338349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3461 images belonging to 3 classes.\n",
            "Found 1482 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "path = \"/content/drive/MyDrive\"\n",
        "batch_size = 32\n",
        "image_length = 128\n",
        "image_size = (image_length, image_length)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.3)\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    shuffle = True,\n",
        "    seed = 4243,\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "validation_batches = train_datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    shuffle = True,\n",
        "    seed = 4243,\n",
        "    subset = \"validation\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oEpBUjoR6_JY"
      },
      "outputs": [],
      "source": [
        "# For Visualization of images and labels\n",
        "def plot_images(image_array):\n",
        "    num_images_per_row = 5\n",
        "    num_images = len(image_array)\n",
        "    num_rows = num_images // num_images_per_row\n",
        "    if num_rows * 5 < num_images: num_rows += 1\n",
        "    fig, axes = plt.subplots(num_rows, num_images_per_row)\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(image_array, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "LABELS = {0: \"Carrying\", 1: \"Normal\", 2: \"Threat\"}\n",
        "def print_label(labels):\n",
        "    if labels.shape == (3,):\n",
        "        print(LABELS[np.where(labels == 1)[0][0]])\n",
        "        return\n",
        "    for label in labels:\n",
        "        print(LABELS[np.where(label == 1)[0][0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsUUFZjK3dTe"
      },
      "outputs": [],
      "source": [
        "images, labels = train_batches[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk1bNgbJ7WN8"
      },
      "outputs": [],
      "source": [
        "# plot_images(images)\n",
        "# print_label(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2LxX3bZ-k6R"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5eJLoXYsF8dE"
      },
      "outputs": [],
      "source": [
        "# Create a VGG 16 model\n",
        "def create_model(type = \"VGG16\"):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(input_shape=(image_length,image_length,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=4096,activation=\"relu\"))\n",
        "    model.add(Dense(units=4096,activation=\"relu\"))\n",
        "    model.add(Dense(units=3, activation=\"softmax\")) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ-jQNspCLBz"
      },
      "outputs": [],
      "source": [
        "# Cell to start training (DO NOT RUN UNLESS FIRST TIME TRAINING)\n",
        "model = create_model()\n",
        "\n",
        "# https://stackoverflow.com/questions/71799046/model-fit-gives-invalidargumenterror-graph-execution-error\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy', metrics.categorical_accuracy])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "FOLfuyvOuCyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3z5Dwk1BYok",
        "outputId": "77877610-510d-471a-a9da-52b717a3e17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "109/109 [==============================] - 3659s 33s/step - loss: 1.1098 - accuracy: 0.3721 - categorical_accuracy: 0.3721 - val_loss: 1.0953 - val_accuracy: 0.3758 - val_categorical_accuracy: 0.3758\n",
            "Epoch 2/5\n",
            "109/109 [==============================] - 2865s 26s/step - loss: 1.0956 - accuracy: 0.3756 - categorical_accuracy: 0.3756 - val_loss: 1.0950 - val_accuracy: 0.3758 - val_categorical_accuracy: 0.3758\n",
            "Epoch 3/5\n",
            "109/109 [==============================] - 2890s 27s/step - loss: 1.0955 - accuracy: 0.3756 - categorical_accuracy: 0.3756 - val_loss: 1.0946 - val_accuracy: 0.3758 - val_categorical_accuracy: 0.3758\n",
            "Epoch 4/5\n",
            "109/109 [==============================] - 2901s 27s/step - loss: 1.0955 - accuracy: 0.3756 - categorical_accuracy: 0.3756 - val_loss: 1.0951 - val_accuracy: 0.3758 - val_categorical_accuracy: 0.3758\n",
            "Epoch 5/5\n",
            "109/109 [==============================] - 2891s 27s/step - loss: 1.0953 - accuracy: 0.3756 - categorical_accuracy: 0.3756 - val_loss: 1.0948 - val_accuracy: 0.3758 - val_categorical_accuracy: 0.3758\n"
          ]
        }
      ],
      "source": [
        "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "history = model.fit(\n",
        "        train_batches,\n",
        "        steps_per_epoch = train_batches.__len__(),\n",
        "        epochs = 5,\n",
        "        validation_data = validation_batches,\n",
        "        validation_steps = validation_batches.__len__())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the training accuracy above, we see that training accuracy converges after 2 epochs. Thus, we can infer that the low accuracy has nothing to do with the number of epochs (as we have already reached convergence). It could be due to:\n",
        "1) Low model complexity (VGG16 is a shallow model with only 2 layers)\n",
        "2) Small image size (resizing to 128x128 removes important information)\n",
        "\n",
        "It is likely not due to lack of image augmentation techniques, which are only added to allow the model to better generalize to testing images."
      ],
      "metadata": {
        "id": "WunIUbiPuNGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model (Not working on Colab)"
      ],
      "metadata": {
        "id": "2K8QxfRpuGWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sVIdN9IoFjNZ"
      },
      "outputs": [],
      "source": [
        "# Not working on Colab\n",
        "model.save_weights('./checkpoints/my_checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHAE6xfNFuqL"
      },
      "outputs": [],
      "source": [
        "# Cell to continue training\n",
        "# Not working on Colab\n",
        "\n",
        "model = create_model()\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy', metrics.categorical_accuracy])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc"
      ],
      "metadata": {
        "id": "I8xWssV5uKSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QsXtzcv-2Fg"
      },
      "outputs": [],
      "source": [
        "# Transfer Learning (To Read Later. Can use ImageNet pre-trained model to (possibly) speed up convergence)\n",
        "# VGG 16: https://keras.io/api/applications/vgg/\n",
        "# https://github.com/bnsreenu/python_for_microscopists/blob/master/Tips_tricks_20_Understanding%20transfer%20learning%20for%20different%20size%20and%20channel%20inputs.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}